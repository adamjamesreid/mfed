# mfed
The mfed pipeline is designed for analysing DamID-seq data. Initially the reads are mapped using the nf-core/chipseq pipeline, then all in silico GATC fragments are filtered based on size and number of mapping reads. The filtered fragments are used as a peakset in DiffBind and DESeq2 is used to look for fragments enriched between Dam-fusion samples and Dam-only samples.

## Setup
1. Install Miniconda if you have not already (for installing various packages)

`wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh`

`bash Miniconda3-latest-Linux-x86_64.sh`

2. Install Nextflow if you do not have it already (for running pipelines)

`conda install -c bioconda nextflow`

Add this line to your .bashrc file

`export NXF_SINGULARITY_CACHEDIR="/mnt/home3/nextflow/"`

3. Install Git if you do not have it already (For downloading code repository)

`conda install -c anaconda git`

4. Pull the mfed git repository

`git clone https://github.com/adamjamesreid/mfed.git`

## Run the pipeline with test data
### Map the reads with nf-core/chipseq 
1. Set up a design file describing the data as described [here](https://nf-co.re/chipseq/1.2.2/usage), for testing use 'mapping_design_test.csv' from this repository. Make sure you have the full paths to the fastq files

2. Run nf-core/chipseq (--macs_gsize is set to 0 so that it doesn't run MACS2 and fall over because it can't calculate t for single-end damid reads)

`nextflow run nf-core/chipseq -r 1.2.2 -profile singularity -c /mnt/home3/nextflow/gurdon.config --single_end --genome dm6 --input mfed/mapping_design_test.csv --macs_gsize 0`

n.b. this step helpfully removes duplicates and multimapping reads

### Run mfed nextflow script 

1. Copy bam files and indexes to current directory

`cp results/bwa/mergedLibrary/*bam* .`

2. Set up a samplesheet for mfed describing the data (this is formatted a bit differently to the one for nf-core/chipseq and conforms to the format of DiffBind samplesheets described in the "Reading in the peakset" section [here](https://bioconductor.org/packages/devel/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf). The test example file is called mfed_samplesheet_test.csv in this repository.) Note that *filtered_fragments.bed* is the name of a file generated by the mfed.nf pipeline.

3. Run mfed Nextflow pipeline

`nextflow run mfed/mfed.nf --ss mfed/mfed_samplesheet_test.csv --treatment hp1fusion --control damonly --frags mfed/gatc_frags.gtf --outdir outdir --anngtf mfed/dm6.ensGene.gtf --annpriority mfed/annotation_priority.csv --genome results/genome/genome.fa -c /mnt/home3/nextflow/gurdon.config -with-singularity /mnt/home3/nextflow/mfed/mfed_cruk.sif`

n.b. here i use the UCSC version of the ensembl gene set - which has 'chr' prepended to the sequence names, consistent with the dm6 genome version used above for nf-core/chipseq

## Input files
annotation_priority.csv - example file with priority list for fragment annotations using ChIPseeker

dm6.ensGene.gtf - GFT file of genome annotation which works nicely with the dm6 reference

gatc_frags.gtf - GATC fragments file for fly genome

mapping_design_test.csv - example input file for nf-core/chipseq describing the experiment

mfed_cruk.sif - Singularity image required for mfed.nf (this is currently available here /mnt/home3/nextflow/mfed/mfed_cruk.sif)

mfed_samplesheet_test.csv - Example mfed samplesheet for running mfed.nf

results/genome/genome.fa - This is the genome sequence (as used in the nf-core/chipseq pipeline). This is required for making a working IGV tarball

Test fastq files are currently located on the Gurdon cluster here: /mnt/bioinfo_sharing/sharing/brand/mfed/

## Output files

1. From nf-core/chipseq 
* MultiQC results - copy to local machine and view in a web browser

results/multiqc/broadPeak/multiqc_report.html

* BAM files of mapped reads

results/bwa/mergedLibrary/*bam

2. From mfed pipeline (in outdir/ directory)

* *.bw - BigWig files generated from BAM files

* enriched_fragments.bed - BED file of fragments enriched in fusion versus dam-only

* feature_counts.txt - lists every GATC fragment in the genome, describing the size and number of reads mapping to it in each sample

* filtered_fragments.bed - All the fragments which have passed initial filtering and will go into the DiffBind analysis
 
* foldchange.bedgraph - fold changes for significant fragments across the genome (view in IGV)

* MA_plot.pdf - plot of average abundance versus fold change for each fragment

* mfed_results_for_igv.tar.gz - tarball of files to load an IGV session

* results_all.tsv - Details of significant fragments, enriched in both fusion and dam-only, with fold changes and FDRs

* results_annotated.tsv - Details of significant fragments, enriched in fusion versus dam-only, with fold changes and FDRs and nearest gene features

* results.tsv - Details of significant fragments, enriched in fusion versus dam-only, with fold changes and FDRs

* sample_heatmap_plot.pdf - heatmap comparing samples

* sample_pca_plot.pdf - PCA plot comparing samples

* volcano_plot.pdf - volcano plot of fold changes against p values

## More options

You can make your own GATC fragment file using the script mfed/bin/fragment_genome.py, e.g.

`mfed/bin/fragment_genome.py results/genome/genome.fa > gatc_frags.gtf`

When running mfed.nf:
* *--min_reads* sets the minimum number of reads mapping to a fragment across all samples added together for it to pass the inital filtering (default = 10
* *--min_length* sets the minimum length in of a fragment for it to pass initial filtering (default = 300)
* *--control* is the name of the control condition as specified in the samplesheet e.g. damonly
* *--treatment* is the name of the treatment/fusion condition specified in the samplesheet e.g. hp1fusion
* *--fc_cut* is the fold change cutoff to consider a fragment as significant (default = 2)
* *--fdr_cut* is the False Discovery Rate (FDR) cutoff to consider a fragment as significant (default = 0.01)
* *--outdir* is the directory for the output files (default = outdir)
* *--anngtf* is a GTF format file of genome annotation for determining the nearest gene
* *--annlevel* used to determine whether to use gene or transcript features - can be 'gene' or 'transcript' (default = gene)
* *--annpriority* file used to determine the order of priority of annotations e.g. are you most interested in Promoter or Exon features (default = use the file provided in the repository - annotation_priority.csv

## Load an IGV sesssion

The mfed pipeline produces a tarball of files (mfed_results_for_igv.tar.gz), including a IGV session file to browse the results in the IGV genome browser

Copy the tarball to where you can use IGV - for those at Gurdon, this might be your laptop. On your laptop run:

```
mkdir igv_files

cd igv_files

scp <user>@cb-milan1.gurdon.private.cam.ac.uk:<path>/mfed_results_for_igv.tar.gz .

tar -xzvf mfed_results_for_igv.tar.gz
```

Install IGV if you need to from [here](https://software.broadinstitute.org/software/igv/download)

Open IGV, 'File' -> 'Open Session', select *mfed_results_for_igv.tar.gz*

## Singularity image
The software dependencies for mfed.nf are captured in a Singularity image. This can be generated using this Singularity definition file: *mfed_cruk.def*.

It makes use of the DiffBind install in the CRUK DiffBind workshop Singularity image described [here](https://www.cruk.cam.ac.uk/core-facilities/bioinformatics-core/software/diffbind-tool-for-chip-seq-and-atac-seq-analysis)

Build like this: `sudo singularity build mfed_cruk.sif mfed_cruk.def`

## To Do

Generate fragments on the fly in mfed.nf

Try to make it a requirement for only one samplesheet

Generate fragment file with cut sites annotated for viewing in IGV

