# mfed v1.0
The mfed pipeline is designed for analysing DamID-seq data. Initially the reads are mapped using the nf-core/chipseq pipeline, then all in silico GATC fragments are filtered based on size and number of mapping reads. The filtered fragments are used as a peakset in DiffBind and DESeq2 is used to look for fragments enriched between Dam-fusion samples and Dam-only samples.

## Contents

* [Setup](#Setup)

* [Run the pipeline with test data](#Run-the-pipeline-with-test-data)

  * [Map the reads with nf-core/chipseq](#Map-the-reads-with-nf-core/chipseq)
  * [Run mfed nextflow script](#Run-mfed-nextflow-script)

* [Input files](#Input-files)

* [Output files](#Output-files)

* [More options](#More-options)

* [Load an IGV sesssion](#Load-an-IGV-sesssion)

* [Singularity image](#Singularity-image)

* [FAQ](#FAQ)


## Setup
1. Install Miniconda if you have not already (for installing various packages)

`wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh`

`bash Miniconda3-latest-Linux-x86_64.sh`

2. Install Nextflow if you do not have it already (for running pipelines)

`conda install -c bioconda nextflow`

3. Install Git if you do not have it already (For downloading code repository)

`conda install -c anaconda git`

4. Pull the mfed git repository

`git clone https://github.com/adamjamesreid/mfed.git`

## Run the pipeline with test data

N.b. this is designed to work nicely on the Gurdon compute cluster, but will need adapting elsewhere

### Map the reads with nf-core/chipseq 
1. Copy test data to the current directory:

`cp /mnt/bioinfo_sharing/sharing/brand/mfed/*gz .`

2. Set up a design file describing the data as described [here](https://nf-co.re/chipseq/1.2.2/usage). For testing use 'mapping_design_test.csv' from this repository. Make sure you use the full paths to the fastq files, or that they are in the current directory.

3. Run nf-core/chipseq (--macs_gsize is set to 0 so that it doesn't run MACS2 and fall over because it can't calculate t for single-end damid reads)

n.b. If you have a Nexflow version <=21, leave out '-dsl1'

`nextflow run nf-core/chipseq -r 1.2.2 -profile singularity -c /mnt/home3/nextflow/gurdon.config --single_end --genome dm6 --input mfed/mapping_design_test.csv --macs_gsize 0 -dsl1`

n.b. this step helpfully removes duplicates and multimapping reads

### Run mfed nextflow pipeline 

1. Generate a samplesheet for mfed describing the data 

This is formatted a bit differently to the one for nf-core/chipseq and conforms to the format of DiffBind samplesheets described in the "Reading in the peakset" section [here](https://bioconductor.org/packages/devel/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf). The test example file is called mfed_samplesheet_test.csv in this repository. Note that *filtered_fragments.bed* is the name of a file generated by the mfed.nf pipeline. You can use this script to make a DiffBind/mfed samplesheet from the nf-core/chipseq one (the -d argument is the full path to the BAM files generated by nf-core/chipseq):

`mfed/bin/design_to_samplesheet.py -i mfed/mapping_design_test.csv -d $PWD/results/bwa/mergedLibrary/ > mfed_samplesheet_test.csv`

2. Run mfed Nextflow pipeline

n.b. If you have a Nexflow version <=21, leave out '-dsl1'

`nextflow run mfed/mfed.nf --ss mfed_samplesheet_test.csv --treatment hp1fusion --control damonly --frags mfed/gatc_frags.gtf --outdir outdir --anngtf mfed/dm6.ensGene.gtf --annpriority mfed/annotation_priority.csv --genome results/genome/genome.fa -c /mnt/home3/nextflow/gurdon.config -with-singularity /mnt/home3/nextflow/mfed/mfed_cruk.sif -dsl1`

n.b. here i use the UCSC version of the ensembl gene set - which has 'chr' prepended to the sequence names, consistent with the dm6 genome version used above for nf-core/chipseq

## Input files

**annotation_priority.csv** - example file with priority list for fragment annotations using ChIPseeker

**dm6.ensGene.gtf** - GFT file of genome annotation which works nicely with the dm6 reference

**gatc_frags.gtf** - GATC fragments file for fly genome

**mapping_design_test.csv** - example input file for nf-core/chipseq describing the experiment

**mfed_cruk.sif** - Singularity image required for mfed.nf (this is currently available here /mnt/home3/nextflow/mfed/mfed_cruk.sif)

**mfed_samplesheet_test.csv** - Example mfed samplesheet for running mfed.nf

**results/genome/genome.fa** - This is the genome sequence (as used in the nf-core/chipseq pipeline). This is required for making a working IGV tarball

**gurdon.config** - nextflow config file for running jobs on Slurm at the Gurdon Institute

Test fastq files are currently located on the Gurdon cluster here: /mnt/bioinfo_sharing/sharing/brand/mfed/

## Output files

1. From nf-core/chipseq 
* MultiQC results - copy to local machine and view in a web browser

**results/multiqc/broadPeak/multiqc_report.html**

* BAM files of mapped reads

**results/bwa/mergedLibrary/*bam**

2. From mfed pipeline (in outdir/ directory)

* ***.bw** - BigWig files generated from BAM files

* **enriched_fragments.bed** - BED file of fragments enriched in fusion versus dam-only

* **feature_counts.txt** - lists every GATC fragment in the genome, describing the size and number of reads mapping to it in each sample

* **filtered_fragments.bed** - All the fragments which have passed initial filtering and will go into the DiffBind analysis
 
* **foldchange.bedgraph**  - fold changes for significant fragments across the genome (view in IGV)

* **MA_plot.pdf** - plot of average abundance versus fold change for each fragment

* **mfed.RData** - R data object, allowing reanalysis/redrawing of figures etc. (see FAQ for details)

* **mfed_results_for_igv.tar.gz** - tarball of files to load an IGV session

* **results_all.tsv** - Details of significant fragments, enriched in both fusion and dam-only, with fold changes and FDRs

* **results_annotated.tsv** - Details of significant fragments, enriched in fusion versus dam-only, with fold changes and FDRs and nearest gene features

* **results.tsv** - Details of significant fragments, enriched in fusion versus dam-only, with fold changes and FDRs

* **sample_heatmap_plot.pdf** - heatmap comparing samples

* **sample_pca_plot.pdf** - PCA plot comparing samples

* **volcano_plot.pdf** - volcano plot of fold changes against p values

## More options

You can make your own GATC fragment file using the script mfed/bin/fragment_genome.py, e.g.

`mfed/bin/fragment_genome.py results/genome/genome.fa > gatc_frags.gtf`

When running mfed.nf:
* **--min_reads** sets the minimum number of reads mapping to a fragment across all samples added together for it to pass the inital filtering (default = 10
* **--min_length** sets the minimum length in of a fragment for it to pass initial filtering (default = 150)
* **--control** is the name of the control condition as specified in the samplesheet e.g. damonly
* **--treatment** is the name of the treatment/fusion condition specified in the samplesheet e.g. hp1fusion
* **--fc_cut** is the fold change cutoff to consider a fragment as significant (default = 2)
* **--fdr_cut** is the False Discovery Rate (FDR) cutoff to consider a fragment as significant (default = 0.01)
* **--outdir** is the directory for the output files (default = outdir)
* **--anngtf** is a GTF format file of genome annotation for determining the nearest gene
* **--annlevel** used to determine whether to use gene or transcript features - can be 'gene' or 'transcript' (default = gene)
* **--annpriority** file used to determine the order of priority of annotations e.g. are you most interested in Promoter or Exon features (default = use the file provided in the repository - annotation_priority.csv

## Load an IGV sesssion

The mfed pipeline produces a tarball of files (mfed_results_for_igv.tar.gz), including a IGV session file to browse the results in the IGV genome browser

Copy the tarball to where you can use IGV - for those at Gurdon, this might be your laptop. On your laptop run:

```
mkdir igv_files

cd igv_files

scp <user>@cb-milan1.gurdon.private.cam.ac.uk:<path>/mfed_results_for_igv.tar.gz .

tar -xzvf mfed_results_for_igv.tar.gz
```

Install IGV if you need to from [here](https://software.broadinstitute.org/software/igv/download)

Open IGV, 'File' -> 'Open Session', select *mfed_results_for_igv.tar.gz*

## Singularity image
The software dependencies for mfed.nf are captured in a Singularity image. This can be generated using this Singularity definition file: *mfed_cruk.def*.

It makes use of the DiffBind install in the CRUK DiffBind workshop Singularity image described [here](https://www.cruk.cam.ac.uk/core-facilities/bioinformatics-core/software/diffbind-tool-for-chip-seq-and-atac-seq-analysis)

Build like this: `sudo singularity build mfed_cruk.sif mfed_cruk.def`

## FAQ

## To Do

Generate fragments on the fly in mfed.nf

Try to make it a requirement for only one samplesheet

Generate fragment file with cut sites annotated for viewing in IGV

